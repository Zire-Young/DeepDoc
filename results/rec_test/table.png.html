
    <html>
    <head>
    <style>
    ._table_1nkzy_11 {
      margin: auto;
      width: 70%;
      padding: 10px;
    }
    ._table_1nkzy_11 p {
      margin-bottom: 50px;
      border: 1px solid #e1e1e1;
    }

    caption {
      color: #6ac1ca;
      font-size: 20px;
      height: 50px;
      line-height: 50px;
      font-weight: 600;
      margin-bottom: 10px;
    }

    ._table_1nkzy_11 table {
      width: 100%;
      border-collapse: collapse;
    }

    th {
      color: #fff;
      background-color: #6ac1ca;
    }

    td:hover {
      background: #c1e8e8;
    }

    tr:nth-child(even) {
      background-color: #f2f2f2;
    }

    ._table_1nkzy_11 th,
    ._table_1nkzy_11 td {
      text-align: center;
      border: 1px solid #ddd;
      padding: 8px;
    }
    </style>
    </head>
    <body>
    <table>
<tr><th></th><th  >Benchmark (Metric)</th><th  >Sonnet-1022</th><th  >0513</th><th  >Claude-3.5-GPT-4oDeepSeek V3</th><th  >01-mini</th><th  >01-1217</th><th  >OpenAIOpenAIDeepSeek R1</th></tr>
<tr><th></th><th  >Architecture #Activated Params #Total Params</th><th></th><th></th><th  >MoE 37B 671B</th><th  >-</th><th></th><th  >MoE 37B 671B</th></tr>
<tr><td></td><td  >MMLU (Pass@1)</td><td  >88.3</td><td  >87.2</td><td  >88.5</td><td  >85.2</td><td  >91.8</td><td  >90.8</td></tr>
<tr><td></td><td  >MMLU-Redux (EM)</td><td  >88.9</td><td  >88.0</td><td  >89.1</td><td  >86.7</td><td></td><td  >92.9</td></tr>
<tr><td></td><td  >MMLU-Pro (EM)</td><td  >78.0</td><td  >72.6</td><td  >75.9</td><td  >80.3</td><td  >=</td><td  >84.0</td></tr>
<tr><td></td><td  >DROP (3-shot F1)</td><td  >88.3</td><td  >83.7</td><td  >91.6</td><td  >83.9</td><td  >90.2</td><td  >92.2</td></tr>
<tr><td></td><td  >IF-Eval (Prompt Strict)</td><td  >86.5</td><td  >84.3</td><td  >86.1</td><td  >84.8</td><td></td><td  >83.3</td></tr>
<tr><td  >English</td><td  >GPQA Diamond (Pass@1)</td><td  >65.0</td><td  >49.9</td><td  >59.1</td><td  >60.0</td><td  >75.7</td><td  >71.5</td></tr>
<tr><td></td><td  >SimpleQA (Correct)</td><td  >28.4</td><td  >38.2</td><td  >24.9</td><td  >7.0</td><td  >47.0</td><td  >30.1</td></tr>
<tr><td></td><td  >FRAMES (Acc.)</td><td  >72.5</td><td  >80.5</td><td  >73.3</td><td  >76.9</td><td  >-</td><td  >82.5</td></tr>
<tr><td></td><td  >AlpacaEval2.0 (LC-winrate)</td><td  >52.0</td><td  >51.1</td><td  >70.0</td><td  >57.8</td><td></td><td  >87.6</td></tr>
<tr><td></td><td  >ArenaHard (GPT-4-1106)</td><td  >85.2</td><td  >80.4</td><td  >85.5</td><td  >92.0</td><td></td><td  >92.3</td></tr>
<tr><td></td><td  >LiveCodeBench(Pass@l-CoT)</td><td  >38.9</td><td  >32.9</td><td  >36.2</td><td  >53.8</td><td  >63.4</td><td  >65.9</td></tr>
<tr><td></td><td  >Codeforces (Percentile)</td><td  >20.3</td><td  >23.6</td><td  >58.7</td><td  >93.4</td><td  >96.6</td><td  >96.3</td></tr>
<tr><td  >Code</td><td  >Codeforces (Rating)</td><td  >717</td><td  >759</td><td  >1134</td><td  >1820</td><td  >2061</td><td  >2029</td></tr>
<tr><td></td><td  >SWE Verified (Resolved)</td><td  >50.8</td><td  >38.8</td><td  >42.0</td><td  >41.6</td><td  >48.9</td><td  >49.2</td></tr>
<tr><td></td><td  >Aider-Polyglot (Acc)</td><td  >45.3</td><td  >16.0</td><td  >49.6</td><td  >32.9</td><td  >61.7</td><td  >53.3</td></tr>
<tr><td  >Math</td><td  >AIME 2024 (Pass@1) MATH-500 (Pass@1) CNMO 2024 (Pass@1)</td><td  >16.0 78.3 13.1</td><td  >9.3 74.6 10.8</td><td  >39.2 90.2 43.2</td><td  >63.6 90.0 67.6</td><td  >79.2 96.4</td><td  >79.8 97.3 78.8</td></tr>
<tr><td  rowspan=3 >Chinese C-Eval (EM)</td><td  >CLUEWSC (EM)</td><td  >85.4</td><td  >87.9</td><td  >90.9</td><td  >89.9</td><td></td><td  >92.8</td></tr>
<tr><td></td><td  >76.7</td><td  >76.0</td><td  >86.5</td><td  >68.9</td><td></td><td  >91.8</td></tr>
<tr><td  >C-SimpleQA (Correct)</td><td  >55.4</td><td  >58.7</td><td  >68.0</td><td  >40.3</td><td></td><td  >63.7</td></tr>
<tr><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th  >Table4|ComparisonbetweenDeepSeek-R1 and otherrepresentative models.</th></tr>
</table>
    </body>
    </html>
